---
layout: page
title: A Study of LLM's Ability to Perform Basic Math Operations in Different Bases
description: # with background image
img: assets/img/llmath.jpg
importance: 2
category: current
related_publications: false
---

Large Language Models have demonstrated remarkable proficiency in a variety of natural language processing tasks, including translation, question-answering, and fill-in-the-blank exercises, with some evidence of reasoning abilities. In this paper, I explore their mathematical reasoning abilities through their performance on simple mathematical tasks. By evaluating GPT-3.5 turbo and GPT-4o on tasks involving addition, subtraction, and multiplication in uncommon numerical bases, this study aims to shed light on the modelsâ€™ ability to generalize to unfamiliar data and their underlying reasoning potential. The results offer insights into the strengths and limitations of LLMs in performing arithmetic operations outside the familiar base-10 system, contributing to a deeper understanding of their reasoning capacities.
